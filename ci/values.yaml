mode: daemonset

extraVolumes:
 - name: varlogpods
   hostPath:
     path: /var/log/pods
extraVolumeMounts:
 - name: varlogpods
   mountPath: /var/log/pods
image:
  repository: 172597598159.dkr.ecr.us-east-1.amazonaws.com/otel-collector-contrib
  tag: ""
securityContext:
  runAsUser: 0
  runAsGroup: 0
resources:
  limits:
    cpu: 512m
    memory: 2Gi
useGOMEMLIMIT: true
presets:
  # logsCollection:
  #   enabled: true
  #   includeCollectorLogs: true
  #   storeCheckpoints: false
  hostMetrics:
    enabled: true
  kubernetesAttributes:
    enabled: true
  kubernetesEvents:
    enabled: true
  kubeletMetrics:
    enabled: true
extraEnvs:
  - name: POD_IP
    valueFrom:
      fieldRef:
        fieldPath: status.podIP
  - name: OTEL_RESOURCE_ATTRIBUTES
    value: "k8s.pod.ip=$(POD_IP)"
  - name: DD_API_KEY
    valueFrom:
      secretKeyRef:
        name: datadog-secrets
        key: api-key
        optional: false
  - name: OTEL_K8S_NAMESPACE
    valueFrom:
      fieldRef:
        apiVersion: v1
        fieldPath: metadata.namespace
config:
  receivers:
    filelog:
      include_file_path: true
      poll_interval: 500ms
      include:
        - /var/log/pods/*/*/*.log
      operators:
        # Find out which format is used by kubernetes
        - type: router
          id: get-format
          routes:
            - output: parser-docker
              expr: 'body matches "^\\{"'
            - output: parser-crio
              expr: 'body matches "^[^ Z]+ "'
            - output: parser-containerd
              expr: 'body matches "^[^ Z]+Z"'
        # Parse CRI-O format
        - type: regex_parser
          id: parser-crio
          regex:
            '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
            ?(?P<log>.*)$'
          output: extract_metadata_from_filepath
          timestamp:
            parse_from: attributes.time
            layout_type: gotime
            layout: '2006-01-02T15:04:05.999999999Z07:00'
        # Parse CRI-Containerd format
        - type: regex_parser
          id: parser-containerd
          regex:
            '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
            ?(?P<log>.*)$'
          output: extract_metadata_from_filepath
          timestamp:
            parse_from: attributes.time
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        # Parse Docker format
        - type: json_parser
          id: parser-docker
          output: extract_metadata_from_filepath
          timestamp:
            parse_from: attributes.time
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        - type: move
          from: attributes.log
          to: body
        # Extract metadata from file path
        - type: regex_parser
          id: extract_metadata_from_filepath
          regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
          parse_from: attributes["log.file.path"]
          cache:
            size: 128 # default maximum amount of Pods per Node is 110
        # Rename attributes
        - type: move
          from: attributes.stream
          to: attributes["log.iostream"]
        - type: move
          from: attributes.container_name
          to: resource["k8s.container.name"]
        - type: move
          from: attributes.namespace
          to: resource["k8s.namespace.name"]
        - type: move
          from: attributes.pod_name
          to: resource["k8s.pod.name"]
        - type: move
          from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
        - type: move
          from: attributes.uid
          to: resource["k8s.pod.uid"]
    jaeger: null
    zipkin: null
    hostmetrics:
      scrapers:
        paging:
          metrics:
            system.paging.utilization:
              enabled: true
        cpu:
          metrics:
            system.cpu.utilization:
              enabled: true
        disk:
        load:
        memory:
        network:
        processes:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
  exporters:
    # Disable debug exporter until we pull change that adds it from upstream
    debug: null
    logging:
      verbosity: detailed
    datadog:
      host_metadata:
        tags: ['env:${env:OTEL_K8S_NAMESPACE}']
      metrics:
        resource_attributes_as_tags: true
        histograms:
          mode: counters
          send_count_sum_metrics: true
      traces:
        span_name_as_resource_name: true
        compute_stats_by_span_kind: true
        peer_service_aggregation: true
      api:
        key: "$DD_API_KEY"
  processors:
    attributes:
      actions:
      - key: log.file.path
        pattern: \/var\/log\/pods\/otel_opentelemetry-demo-(?P<service_name>.*?)-.*
        action: extract
      - key: log.file.path
        pattern: \/var\/log\/pods\/otel_opentelemetry-demo-(?P<source>.*?)-.*
        action: extract
      - key: service
        from_attribute: service_name
        action: upsert
    attributes/kafkasrc:
      include:
        match_type: regexp
        attributes:
          - {key: "source", value: 'kafka|frauddetectionservice|orderproducer'}
      actions:
      # this makes sure the source for logs that come from kafka|frauddetectionservice|orderproducer is
      # set to kafka. The OOTB box kafka dashboard filters logs on source:kafka. This will still not work
      # as it will be a log attribute and can only be searched by @source:kafka. We would need to support
      # attributes_as_tags or find another solution for this to work.
      - key: source
        action: update
        value: "kafka"
    memory_limiter:
      check_interval: 1s
      limit_mib: 500
    resourcedetection:
      # ensures host.name and other important resource tags
      # get picked up
      detectors: [env, gcp, ecs, ec2, azure, system]
      timeout: 5s
      override: false
    # adds various tags related to k8s
    # adds various tags related to k8s
    k8sattributes:
      passthrough: false
      auth_type: "serviceAccount"
      pod_association:
        - sources:
            - from: resource_attribute
              name: k8s.pod.ip
      extract:
        metadata:
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.deployment.name
          - k8s.node.name
          - k8s.namespace.name
          - k8s.pod.start_time
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.name
          - container.image.tag
          - container.id
          - k8s.container.name
          - container.image.name
          - container.image.tag
          - container.id
        labels:
          - tag_name: kube_app_name
            key: app.kubernetes.io/name
            from: pod
          - tag_name: kube_app_instance
            key: app.kubernetes.io/instance
            from: pod
          - tag_name: kube_app_version
            key: app.kubernetes.io/version
            from: pod
          - tag_name: kube_app_component
            key: app.kubernetes.io/component
            from: pod
          - tag_name: kube_app_part_of
            key: app.kubernetes.io/part-of
            from: pod
          - tag_name: kube_app_managed_by
            key: app.kubernetes.io/managed-by
            from: pod
    batch:
      send_batch_max_size: 1000
      send_batch_size: 100
      timeout: 10s
  service:
    telemetry:
      logs:
        encoding: "json"
        initial_fields:
          - service: "otel-collector"
    pipelines:
      metrics:
        receivers: [otlp, hostmetrics, prometheus]
        processors: [resourcedetection, k8sattributes, batch]
        exporters: [datadog]
      traces:
        receivers: [otlp]
        processors: [resourcedetection, k8sattributes, batch]
        exporters: [datadog]
      logs:
        receivers: [filelog]
        processors: [memory_limiter, resourcedetection, k8sattributes, attributes, attributes/kafkasrc, batch]
        exporters: [datadog]